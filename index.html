<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Jiyeon Han</title>

    <meta name="author" content="Jiyeon Han">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/jiyeon_notion.png" type="image/png">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Jiyeon Han
                </p>
                <p>
		About Me
		I’m Jiyeon Han, a researcher in AI, currently beginning my postdoctoral position in the <a href="https://gruvi.cs.sfu.ca">GrUVi Lab</a> at the School of Computing Science, <a href="https://www.sfu.ca">Simon Fraser University</a>, under the supervision of <a href="https://www.cs.sfu.ca/~haoz/">Prof. Hao (Richard) Zhang</a>. 
		I recently completed my Ph.D. at <a href="https://gsai.kaist.ac.kr">KAIST</a>, Korea, advised by <a href="https://sailab.kaist.ac.kr/members/jaesik/">Prof. Jaesik Choi</a>. 
		My dissertation, “Computational Creativity in AI: Assessing and Enhancing the Creative Output of Generative Models,” 
		reflects my core research interests in developing reliable methods for evaluating creativity and enhancing the creative capabilities of generative models.
                </p>
                <p style="text-align:center">
                  <a href="mailto:jyhan.20@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/Jiyeon_s_CV-2025_v2.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=56Uih48AAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/jhan-ai">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://github.com/han-j-y/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/IMG_8616.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/IMG_8616.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I’m interested in building creative AI through generative models, with a broader focus on pushing the boundaries of what AI can achieve. I’m also deeply interested in understanding and analyzing the internal mechanisms of AI models to gain insights into how they learn, generate, and reason.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


<!--     <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()"  bgcolor="#ffffd0">
      <td style="padding:16px;width:30%;vertical-align:middle">
        <div class="one">
          <div class="two" id='bolt3d_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/bolt3d.mp4" type="video/mp4">
          Your browser does not support the video tag.

          </video></div>
          <img src='images/bolt3d.jpg' width="160">
        </div>
        <script type="text/javascript">
          function bolt3d_start() {
            document.getElementById('bolt3d_image').style.opacity = "1";
          }

          function bolt3d_stop() {
            document.getElementById('bolt3d_image').style.opacity = "0";
          }
          bolt3d_stop()
        </script>
      </td>
      <td style="padding:8px;width:70%;vertical-align:middle">
        <a href="https://szymanowiczs.github.io/bolt3d">
          <span class="papertitle">Bolt3D: Generating 3D Scenes in Seconds</span>
        </a>
        <br>
        <a href="https://szymanowiczs.github.io/">Stanislaw Szymanowicz</a>,
        <a href="https://jasonyzhang.com">Jason Y. Zhang</a>,
        <a href="https://pratulsrinivasan.github.io">Pratul Srinivasan</a>,
        <a href="https://ruiqigao.github.io">Ruiqi Gao</a>,
        <a href="https://github.com/ArthurBrussee">Arthur Brussee</a>,
        <a href="https://holynski.org">Aleksander Holynski</a>,
        <a href="https://ricardomartinbrualla.com">Ricardo Martin-Brualla</a>,
		<strong>Jonathan T. Barron</strong>,
        <a href="https://henzler.github.io">Philipp Henzler</a>
        <br>
        <em>ICCV</em>, 2025
        <br>
        <a href="https://szymanowiczs.github.io/bolt3d">project page</a>
        /
        <a href="https://szymanowiczs.github.io/bolt3d">arXiv</a>
        <p></p>
        <p>
		By training a latent diffusion model to directly output 3D Gaussians we enable fast (~6 seconds on a single GPU) feed-forward 3D scene generation.
        </p>
      </td>
    </tr> -->
	<tr>
              <td style="padding:16px;width:30%;vertical-align:middle">
                <img src="images/c3.png" alt="c3" width="240" style="border-style: none">
              </td>
              <td style="padding:8px;width:70%;vertical-align:middle">
                <a href="https://openaccess.thecvf.com/content/CVPR2025/html/Han_Enhancing_Creative_Generation_on_Stable_Diffusion-based_Models_CVPR_2025_paper.html">
                  <span class="papertitle">Enhancing Creative Generation on Stable Diffusion-based Models</span>
                </a>
                <br>
	        <strong>Jiyeon Han*</strong>,
                <a href="https://github.com/daheekwon/">Dahee Kwon*</a>,
                <a href="https://sites.google.com/site/gylee1103/">Gayoung Lee</a>,
                <a href="https://github.com/taki0112/">Junho Kim</a>,
                <a href="https://sailab.kaist.ac.kr/members/jaesik/">Jaesik Choi</a>
		      (* contributed equally)
                <br>
                <em>CVPR</em>, 2025
                <br>
                <a href="https://github.com/daheekwon/C3">github</a> /
                <a href="https://arxiv.org/abs/2503.23538">arxiv</a>
                <p>We present a training-free approach to enhance creative generation on Stable-Diffusion-based models. We achieve this by amplifying low-frequency features in the shallow blocks in the pretrained models.</p>
              </td>
            </tr>

	<tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/diverse_rare.png" alt="diverse_rare" width="240" style="border-style: none">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://ojs.aaai.org/index.php/AAAI/article/view/32480">
                  <span class="papertitle">Diverse Rare Sample Generation with Pretrained GANs</span>
                </a>
                <br>
                <a href="https://sailab.kaist.ac.kr/members/subeen_lee/">Subeen Lee</a>,
	        <strong>Jiyeon Han</strong>,
                <a href="https://sailab.kaist.ac.kr/members/soyeon_kim/">Soyeon Kim</a>,
                <a href="https://sailab.kaist.ac.kr/members/jaesik/">Jaesik Choi</a>
                <br>
                <em>AAAI</em>, 2025
                <br>
                <a href="https://github.com/sbrblee/DivRareGen">github</a> /
                <a href="https://arxiv.org/abs/2412.19543">arxiv</a>
                <p>This work explores a method for generating diverse rare samples that remain faithful to the original outputs of a pretrained GAN. By leveraging Normalizing Flows for density estimation, we enable end-to-end optimization to produce samples with lower data likelihood. </p>
              </td>
            </tr>

	<tr bgcolor="#ffffd0">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/rarity.png" alt="rarity" width="240" style="border-style: none">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://openreview.net/forum?id=JTGimap_-F">
                  <span class="papertitle">Rarity Score : A New Metric to Evaluate the Uncommonness of Synthesized Images</span>
                </a>
                <br>
	        <strong>Jiyeon Han</strong>,
                <a href="https://github.com/hichoe95/">Hwanil Choi</a>,
                <a href="https://yunjey.github.io/">Yunjey Choi</a>,
                <a href="https://github.com/taki0112/">Junho Kim</a>,
                <a href="https://aidljwha.wordpress.com/">Jung-Woo Ha</a>,
                <a href="https://sailab.kaist.ac.kr/members/jaesik/">Jaesik Choi</a>
                <br>
                <em>ICLR</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
                <br>
                <a href="https://github.com/hichoe95/Rarity-Score">github</a> /
                <a href="https://arxiv.org/abs/2206.08549">arxiv</a>
                <p>We present a new metric to assess rareness of an individual generated sample from pretrained generative models. Rarity score computes the (inverse) density of the sample estimated by k-NN based data manifold of real training data. </p>
              </td>
            </tr>

	<tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/unsupervised_way.png" alt="unsupervised_way" width="240" style="border-style: none">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://ojs.aaai.org/index.php/AAAI/article/view/19989">
                  <span class="papertitle">An Unsupervised Way to Understand Artifact Generating Internal Units in Generative Neural Networks</span>
                </a>
                <br>
                <a href="https://creative.sogang.ac.kr/a6/">Haedong Jeong</a>,
		<strong>Jiyeon Han</strong>,
                <a href="https://sailab.kaist.ac.kr/members/jaesik/">Jaesik Choi</a>
                <br>
                <em>AAAI</em>, 2022
                <br>
                <a href="https://arxiv.org/abs/2112.08814">arxiv</a>
                <p>We investigate internal neurons that are closely associated with defective generations in generative neural networks. Our analysis reveals that neurons corresponding to artifact regions often exhibit abrupt local activation changes. Based on this observation, we propose the Local Activation Score to identify artifact-related neurons.</p>
              </td>
            </tr>

	  <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/automatic_correction.png" alt="automatic_correction" width="240" style="border-style: none">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://openaccess.thecvf.com/content/CVPR2021/html/Tousi_Automatic_Correction_of_Internal_Units_in_Generative_Neural_Networks_CVPR_2021_paper.html">
                  <span class="papertitle">Automatic Correction of Internal Units in Generative Neural Networks</span>
                </a>
                <br>
                <a href="https://www.linkedin.com/in/litoali/">Ali Tousi*</a>,
                <a href="https://creative.sogang.ac.kr/a6/">Haedong Jeong*</a>,
		<strong>Jiyeon Han</strong>,
	        <a href="https://github.com/hichoe95/">Hwanil Choi</a>,
                <a href="https://sailab.kaist.ac.kr/members/jaesik/">Jaesik Choi</a>
		      (* equally contributed)
                <br>
                <em>CVPR</em>, 2021
                <br>
                <a href="https://arxiv.org/abs/2104.06118">arxiv</a>
                <p>This work proposes a method for automatically identifying internal feature maps responsible for defective generations. By training an external artifact classifier and applying the explainable AI technique Grad-CAM, we highlight the feature maps most strongly associated with artifact regions. Building on this, we introduce a sequential correction algorithm that progressively refines the generation by suppressing artifact-related activations. </p>
              </td>
            </tr>
		  
	<tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/cbocpd.gif" alt="cbocpd" width="240" style="border-style: none">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://www.ijcai.org/Proceedings/2019/0340.pdf">
                  <span class="papertitle">Confirmatory Bayesian Online Change Point Detection in the Covariance Structure of Gaussian Processes</span>
                </a>
                <br>
		<strong>Jiyeon Han*</strong>,
                <a href="https://leekwoon.github.io/">Kyowoon Lee*</a>,
	        <a href="https://anh-tong.github.io/">Anh Tong</a>,
                <a href="https://sailab.kaist.ac.kr/members/jaesik/">Jaesik Choi</a>
		      (* equally contributed)
                <br>
                <em>IJCAI</em>, 2019
                <br>
	        <a href="https://leekwoon.github.io/projects/cbocpd/">project page</a> /
                <a href="https://arxiv.org/abs/1905.13168">arxiv</a>
                <p>This work proposes a method for automatically identifying internal feature maps responsible for defective generations. By training an external artifact classifier and applying the explainable AI technique Grad-CAM, we highlight the feature maps most strongly associated with artifact regions. Building on this, we introduce a sequential correction algorithm that progressively refines the generation by suppressing artifact-related activations. </p>
              </td>
            </tr>

<!-- 		  
		  
    <tr onmouseout="ever_stop()" onmouseover="ever_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='ever_image'>
					  <img src='images/ever_after.png' width=100%>
					</div>
          <img src='images/ever_before.png' width=100%>
        </div>
        <script type="text/javascript">
          function ever_start() {
            document.getElementById('ever_image').style.opacity = "1";
          }

          function ever_stop() {
            document.getElementById('ever_image').style.opacity = "0";
          }
          ever_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://half-potato.gitlab.io/posts/ever/">
			<span class="papertitle">EVER: Exact Volumetric Ellipsoid Rendering for Real-time View Synthesis
</span>
        </a>
        <br>
				<a href="https://half-potato.gitlab.io/">Alexander Mai</a>, 
				<a href="https://phogzone.com/">Peter Hedman</a>,
				<a href="https://grgkopanas.github.io/">George Kopanas</a>,
        <a href="https://dorverbin.github.io/">Dor Verbin</a>,
        <a href="https://scholar.google.com/citations?user=ozNFrecAAAAJ&hl=en">David Futschik</a>,
        <a href="https://xharlie.github.io/">Qiangeng Xu</a>,
        <a href="https://jacobsschool.ucsd.edu/faculty/profile?id=253">Falko Kuester</a>,
				<strong>Jonathan T. Barron</strong>,
        <a href="https://www.zhangyinda.com/">Yinda Zhang</a>
				<br>
        <em>ICCV</em>, 2025
        <br>
        <a href="https://half-potato.gitlab.io/posts/ever/">project page</a>
        /
        <a href="https://arxiv.org/abs/2410.01804">arXiv</a>
        <p></p>
        <p>
				Raytracing constant-density ellipsoids yields more accurate and flexible radiance fields than splatting Gaussians, and still runs in real-time.
        </p>
      </td>
    </tr>


    <tr onmouseout="cat4d_stop()" onmouseover="cat4d_start()" bgcolor="#ffffd0">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='cat4d_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/cat4d.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/cat4d.jpg' width="160">
        </div>
        <script type="text/javascript">
          function cat4d_start() {
            document.getElementById('cat4d_image').style.opacity = "1";
          }

          function cat4d_stop() {
            document.getElementById('cat4d_image').style.opacity = "0";
          }
          cat4d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://cat-4d.github.io/">
			<span class="papertitle">CAT4D: Create Anything in 4D with Multi-View Video Diffusion Models
</span>
        </a>
        <br>
				<a href="https://www.cs.columbia.edu/~rundi/">Rundi Wu</a>,
				<a href="https://ruiqigao.github.io/">Ruiqi Gao</a>,
				<a href="https://poolio.github.io/">Ben Poole</a>,
				<a href="https://alextrevithick.github.io/">Alex Trevithick</a>,
				<a href="https://www.cs.columbia.edu/~cxz/index.htm/">Changxi Zheng</a>,
				<strong>Jonathan T. Barron</strong>,
				<a href="https://holynski.org/">Aleksander Holynski</a>
        <br>
        <em>CVPR</em>, 2025 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
        <br>
        <a href="https://cat-4d.github.io/">project page</a>
        /
        <a href="https://arxiv.org/abs/2411.18613">arXiv</a>
        <p></p>
        <p>
				An approach for turning a video into a 4D radiance field that can be rendered in real-time. When combined with a text-to-video model, this enables text-to-4D.
        </p>
      </td>
    </tr> -->


    
          </tbody></table>

          
					<table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
           
<!--             <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #fcb97d;">
								 <h2>Micropapers</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
                <br>
                <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
                <br>
                <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
                <br>
                <a href="https://jonbarron.info/data/cvpr2023_llm_workshop_annotated.pdf">Scholars & Big Models: How Can Academics Adapt?</a>
              </td>
            </tr>
 -->

            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #aaba9e;">
								 <h2>Invited Talks</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">			  
                LG AI Seminar, 2025<br>				  
                Ai4 Research Summit, 2024<br>				  
              </td>
            </tr>

<!--             <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #c6b89e;">
								 <h2>Academic Service</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://iccv.thecvf.com/">Lead Area Chair, ICCV 2025</a>
                <br>
                <a href="https://cvpr.thecvf.com/Conferences/2025/Organizers">Lead Area Chair, CVPR 2025</a>
                <br>
                <a href="https://cvpr.thecvf.com/Conferences/2024/Organizers">Area Chair, CVPR 2024</a>
                <br>
                <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>
                <br>
                <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                <br>
                <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Award Committee Member, CVPR 2021</a>
                <br>
                <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                <br>
                <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
              </td>
            </tr>
						 -->
						
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #edd892;">
								 <h2>Teaching</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                TA - Deep Learning, Fall 2021
                <br>
                TA - AI-based Time Series Analysis, Spring 2021
                <br>
                TA - Deep Learning, Fall 2020
                <br>
                TA - Interpretability and Interactivity in AI, Spring 2020
                <br>
                TA - Star-MOOC, Fall 2018
                <br>
                TA - Principles of Programming Languages, Spring 2018
                <br>
              </td>
            </tr>
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  This website is built upon <a href="https://jonbarron.info">Jon Barron</a>'s <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. 
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
